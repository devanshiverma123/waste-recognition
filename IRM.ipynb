{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pickle.load(open('mainmodel.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "waste_classes = {\n",
    "    '0' : 'Book/Magazine',\n",
    "    '1' : 'Cardboard',\n",
    "    '2' : 'Cutlery/Utensils',\n",
    "    '3' : 'Electrical Device',\n",
    "    '4' : 'Glass Bottle',\n",
    "    '5' : 'Glass Jar',\n",
    "    '6' : 'Metal Cans',\n",
    "    '7' : 'Newspaper',\n",
    "    '8' : 'Paper',\n",
    "    '9' : 'Plastic Bag',\n",
    "    '10' : 'Plastic Bottle',\n",
    "    '11' : 'Plate/ Tray',\n",
    "    '12' : 'Toiletry',\n",
    "    '13' : 'Vegetable/Fruit'\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = lambda imname: np.asarray(Image.open(imname).convert(\"RGB\").resize((224,224)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv2.VideoCapture(0)\n",
    "final_result = ''\n",
    "while True:\n",
    "    \n",
    "        _, frame = video.read()\n",
    " \n",
    "        start_point = (160,160)\n",
    "        end_point = (440,440)\n",
    "        color =  (0,225,0)\n",
    "        thickness = 2\n",
    "        \n",
    "        frame = cv2.rectangle(frame, start_point , end_point , color , thickness) \n",
    "        tic1 = time.time()\n",
    "        #Resizing into 224x224 because we trained the model with this image size and changing to RGB channel\n",
    "        im = Image.fromarray(frame, 'RGB') \n",
    "        im = im.resize((224,224))\n",
    "        img_array = np.array(im)\n",
    "\n",
    "        #Our keras model used a 4D tensor, (images x height x width x channel)\n",
    "        #So changing dimension 224x224x3 into 1x224x224x3 \n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "        #Calling the predict method on model\n",
    "        prediction = model.predict(img_array)\n",
    "        class_prediction = np.argmax(prediction, axis=1)\n",
    "    \n",
    "        answer = [v for k,v in waste_classes.items() if str(class_prediction[0]) == k][0] \n",
    "        key=cv2.waitKey(3)\n",
    "        if key == ord('t'):\n",
    "            cv2.putText(frame, answer, (50,50) , cv2.FONT_HERSHEY_SIMPLEX , 2 ,(255, 0, 0),\n",
    "                2,  \n",
    "                cv2.LINE_4)\n",
    "            key=cv2.waitKey(5)\n",
    "            \n",
    "            \n",
    "            \n",
    "        toc1 = time.time()\n",
    "        # Press s only if you want to get DIY ideas \n",
    "        if key == ord('s'):\n",
    "            tic2 = time.time()\n",
    "            cv2.imwrite(filename='saved_img.jpg', img=frame)\n",
    "            img_new = cv2.imread('saved_img.jpg', cv2.IMREAD_GRAYSCALE)\n",
    "            img_new = cv2.imshow(\"Captured Image\", img_new)\n",
    "            \n",
    "            #Here we are storing the image whose DIY hacks we want to know in the testing folder, in a processed form\n",
    "            print(\"Processing image...\")\n",
    "            img_ = cv2.imread('saved_img.jpg', cv2.IMREAD_ANYCOLOR)\n",
    "            print(\"Resizing image to 224x224 scale...\")\n",
    "            img_ = cv2.resize(img_,(224,224))\n",
    "            print(\"Resized...\")\n",
    "            img_resized = cv2.imwrite(filename=r'C:\\Users\\NDH60042\\MAJOR PROJECT\\test\\saved_img-final.jpg', img=img_)\n",
    "            print(\"Image saved!\")\n",
    "            \n",
    "            #Here we are reading the image that just got stored in the test folder\n",
    "            test_data = []\n",
    "            testpath_ = r'C:\\Users\\NDH60042\\MAJOR PROJECT\\test'\n",
    "            testdata_path = os.path.join(testpath_ ,'*g')\n",
    "            test_files = glob.glob(testdata_path)\n",
    "            for f in test_files:\n",
    "                ims = [read(f)]\n",
    "                test_data += ims\n",
    "      \n",
    "            test_array = np.array(test_data , dtype = 'uint8')\n",
    "            \n",
    "            #Predicting the class\n",
    "            prediction = model.predict(test_array)\n",
    "            class_prediction = np.argmax(prediction, axis = 1)\n",
    "            \n",
    "            answer = [v for k,v in waste_classes.items() if str(class_prediction[0]) == k][0]     \n",
    "            \n",
    "            cv2.putText(img_new, answer, (50,50) , cv2.FONT_HERSHEY_SIMPLEX , 2 ,(255, 0, 0),\n",
    "                        2, cv2.LINE_4)\n",
    "            \n",
    "            toc2 = time.time()\n",
    "            #Storing the result whose DIY hacks we want\n",
    "            final_result = answer\n",
    "            cv2.waitKey(1650)\n",
    "            cv2.destroyAllWindows()\n",
    "            \n",
    "            break\n",
    "\n",
    "        cv2.imshow(\"video\", frame)\n",
    "       \n",
    "        if key == ord('q'):\n",
    "                break\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(final_result.split())==2:\n",
    "    search = \"https://www.google.com/search?q=DIY+Reusing+Ideas+for\"+final_result.split()[0]+final_result.split()[1]\n",
    "else:\n",
    "    search = \"https://www.google.com/search?q=DIY+Reusing+Ideas+for\"+final_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webbrowser.open(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>FLASK FUNCTION </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = r'C:\\Users\\NDH60042\\MAJOR PROJECT\\paper1.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.resnet50 import preprocess_input,decode_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(image_file):\n",
    "    image = tf.keras.preprocessing.image.load_img(\n",
    "        image_file, target_size=(224,224)\n",
    "    )\n",
    "    image = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    image = np.array(image)\n",
    "    image = np.expand_dims(image, axis = 0)\n",
    "    image = preprocess_input(image)\n",
    "    \n",
    "    prediction = model.predict(image)\n",
    "    class_prediction = np.argmax(prediction)\n",
    "    print(prediction)\n",
    "    waste_classes = {\n",
    "    '0' : 'Book/Magazine',\n",
    "    '1' : 'Cardboard',\n",
    "    '2' : 'Cutlery/Utensils',\n",
    "    '3' : 'Electrical Device',\n",
    "    '4' : 'Glass Bottle',\n",
    "    '5' : 'Glass Jar',\n",
    "    '6' : 'Metal Cans',\n",
    "    '7' : 'Newspaper',\n",
    "    '8' : 'Paper',\n",
    "    '9' : 'Plastic Bag',\n",
    "    '10' : 'Plastic Bottle',\n",
    "    '11' : 'Plate/ Tray',\n",
    "    '12' : 'Toiletry',\n",
    "    '13' : 'Vegetable/Fruit'\n",
    "     }\n",
    "    result = [v for k,v in waste_classes.items() if k== str(class_prediction)][0]\n",
    "    accuracy = prediction[0][class_prediction]*100\n",
    "    return result,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.91285342e-01 2.20723942e-01 8.53287759e-07 1.44125399e-04\n",
      "  2.72564157e-05 3.95585585e-06 2.33550952e-03 3.05173267e-03\n",
      "  5.81583381e-01 1.28065716e-04 1.37375382e-05 6.90758927e-04\n",
      "  1.13082542e-05 1.01024895e-07]]\n"
     ]
    }
   ],
   "source": [
    "result,accuracy = get_prediction(image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Paper'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58.15833806991577"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jar'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str1 = 'Glass Jar'\n",
    "str1.split()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
